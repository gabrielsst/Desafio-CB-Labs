# ğŸš€ Desafio Engenharia de Dados â€“ Armazenamento de APIs no Data Lake

## âœ… 1. Por que armazenar as respostas das APIs?

Armazenar as respostas das APIs Ã© essencial por vÃ¡rios motivos:

### ğŸ¯ **MotivaÃ§Ãµes principais:**

* **Rastreabilidade e Auditoria**
  Permite acompanhar o histÃ³rico de dados, reprocessar anÃ¡lises e garantir integridade.

* **Desacoplamento de sistemas**
  Evita chamadas frequentes Ã s APIs externas, reduzindo dependÃªncia e melhorando desempenho.

* **Controle de versÃµes de dados**
  MantÃ©m registros conforme os dados evoluem com o tempo.

* **AnÃ¡lise em lote e reprocessamento**
  Permite ETLs periÃ³dicos e uso de ferramentas analÃ­ticas como Spark, Athena ou Presto.

* **Economia de custos e escalabilidade**
  Uma vez armazenado, o dado pode ser processado em larga escala no Data Lake sem penalizar sistemas de origem.

---

## ğŸ—‚ï¸ 2. Como vocÃª armazenaria os dados?

### ğŸ§± Estrutura de Pastas Sugerida (em um Data Lake como S3, GCS, etc.)

```bash
data-lake/
â””â”€â”€ restaurant_chain/
    â””â”€â”€ raw/
        â”œâ”€â”€ bi/
        â”‚   â””â”€â”€ getFiscalInvoice/
        â”‚       â””â”€â”€ year=2024/month=07/day=31/storeId=R001/
        â”‚           â””â”€â”€ response.json
        â”œâ”€â”€ res/
        â”‚   â””â”€â”€ getGuestChecks/
        â”‚       â””â”€â”€ year=2024/month=07/day=31/storeId=R001/
        â”‚           â””â”€â”€ response.json
        â”œâ”€â”€ org/
        â”‚   â””â”€â”€ getChargeBack/
        â”‚       â””â”€â”€ year=2024/month=07/day=31/storeId=R001/
        â”‚           â””â”€â”€ response.json
        â”œâ”€â”€ trans/
        â”‚   â””â”€â”€ getTransactions/
        â”‚       â””â”€â”€ year=2024/month=07/day=31/storeId=R001/
        â”‚           â””â”€â”€ response.json
        â””â”€â”€ inv/
            â””â”€â”€ getCashManagementDetails/
                â””â”€â”€ year=2024/month=07/day=31/storeId=R001/
                    â””â”€â”€ response.json
```

### ğŸ“Œ **Detalhes da Estrutura:**

* `year=YYYY/month=MM/day=DD` âœ particionamento temporal para performance de leitura em ferramentas de anÃ¡lise.
* `storeId=R001` âœ particionamento por loja para facilitar anÃ¡lise segmentada.
* `response.json` âœ arquivo bruto da API, mantendo a estrutura original.

---

## ğŸ” 3. E se a resposta da API mudar? (ex: `taxes` â†’ `taxation`)

### ğŸ“‰ **Impactos:**

* **Falha em ETLs e transformaÃ§Ãµes**
  Scripts e pipelines que esperam a chave `guestChecks.taxes` quebrarÃ£o.

* **Schema drift (deriva de esquema)**
  Dificulta manutenÃ§Ã£o e requer versionamento do schema de leitura.

* **InconsistÃªncia nos dados histÃ³ricos vs atuais**
  Dados anteriores usarÃ£o `taxes`, novos usarÃ£o `taxation`, dificultando anÃ¡lises uniformes.

### ğŸ§  **SoluÃ§Ãµes sugeridas:**

1. **Schema evolution consciente no Data Lake**
   Use ferramentas como Apache Iceberg, Delta Lake ou Glue para adaptar schemas.

2. **Pipeline resiliente ao schema**
   Validar esquema dinamicamente com `try-except`, `dict.get()` ou estruturas de mapeamento.

3. **VersÃ£o de schema no nome da pasta** (opcional):

   ```bash
   getGuestChecks_v2/
   ```

4. **CatalogaÃ§Ã£o e validaÃ§Ã£o com data contracts**
   Definir schemas em JSON Schema ou Avro + contratos em ferramentas como OpenAPI.

---

## ğŸ› ï¸ Processo de Desenvolvimento

* ğŸ“Œ **Input**: Resposta da API (`busDt`, `storeId`)
* â³ **Processo**: Armazenar `response.json` em estrutura versionada e particionada
* âœ… **Output**: Dados acessÃ­veis para anÃ¡lise, histÃ³ricos mantidos, com governanÃ§a clara

---

## ğŸ§ª Exemplo de CÃ³digo Python (Armazenamento em S3)

```python
import boto3
import json
from datetime import date

s3 = boto3.client('s3')
bucket = 'data-lake'
store_id = 'R001'
today = date.today()

# SimulaÃ§Ã£o de endpoint e resposta
endpoint = 'res/getGuestChecks'
payload = {"busDt": today.isoformat(), "storeId": store_id}
response = call_api(endpoint, payload)  # funÃ§Ã£o fictÃ­cia

# Caminho particionado
key = f"restaurant_chain/raw/res/getGuestChecks/year={today.year}/month={today.month:02}/day={today.day:02}/storeId={store_id}/response.json"

# Upload para o S3
s3.put_object(Bucket=bucket, Key=key, Body=json.dumps(response))
```